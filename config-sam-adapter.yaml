# https://github.com/tianrun-chen/SAM-Adapter-PyTorch/blob/main/configs/cod-sam-vit-b.yaml
model:
  name: sam
  args:
    inp_size: 1024
    loss: iou
    encoder_mode:
      name: sam
      img_size: 1024
      mlp_ratio: 4
      patch_size: 16
      qkv_bias: true
      use_rel_pos: true
      window_size: 14
      out_chans: 256
      scale_factor: 32
      input_type: fft
      freq_nums: 0.25
      prompt_type: highpass
      prompt_embed_dim: 256
      tuning_stage: 1234
      handcrafted_tune: true
      embedding_tune: true
      adaptor: adaptor
      embed_dim: 768
      depth: 12
      num_heads: 12
      global_attn_indexes:
      - 2
      - 5
      - 8
      - 11
optimizer:
  name: adamw
  args:
    lr: 0.0002
lr_min: 1.0e-7
epoch_max: 20

multi_step_lr:
  milestones:
  - 1
  gamma: 0.1
epoch_val: 1
epoch_save: 1

#resume: 60
#start_epoch: 60